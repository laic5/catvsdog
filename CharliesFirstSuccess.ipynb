{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat vs. Dog Classification\n",
    "### Colin Santos and Cynthia Lai\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in Train and Test Images\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from imagenet_utils import decode_predictions\n",
    "from imagenet_utils import preprocess_input\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_label(file_name):\n",
    "    \"\"\"Gives binary based on image name\"\"\"\n",
    "    category = file_name.split('.')[0]\n",
    "    if   category == 'cat': return 0 # [1, 0]\n",
    "    elif category == 'dog': return 1 # [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_directory = 'train_small/'\n",
    "# Form list of training images names\n",
    "train_dir_files  = os.listdir(train_directory)\n",
    "# Remove hidden MAC files\n",
    "train_dir_files     = [i for i in train_dir_files if i!= '.DS_Store' ]\n",
    "# Convert to 224 x 224 images\n",
    "# !!! Modify image augmentation/normalization as necessary !!!\n",
    "train_im_list = [Image.open(train_directory + im).resize((224,224)) for im in train_dir_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numPics = len(train_dir_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get training labels \n",
    "train_labels = [get_train_label(file) for file in train_dir_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import _pickle as cPickle\n",
    "import pickle as cPickle\n",
    "f = open(\"im_list.pl\", 'wb') # .pl is a pickle file\n",
    "cPickle.dump(train_im_list, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Formatted data as (numpy arrays of) list of tuples of modified image and respective label or number\n",
    "train_data = [(np.array(train_im, dtype=np.float64), np.array(train_label)) for (train_im, train_label) in zip(train_im_list, train_labels)]\n",
    "#test_data  = [(np.array(test_im), np.array(test_number)) for (test_im, test_number) in zip(test_im_list, test_numbers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the data itself in np.array format\n",
    "train_dat = [np.array(train_im, dtype=np.float64) for train_im in train_im_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IGNORE THIS\n",
    "\n",
    "from keras.preprocessing import image as image_utils\n",
    "\n",
    "im = image_utils.load_img(train_directory + train_dir_files[0], target_size=(224, 224))\n",
    "test = image_utils.img_to_array(train_im_list[0])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, work with VGG16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: \n",
    "1. Rerun line above train_data = [(np. ......]\n",
    "2. Try to do the line below, and then remove the .astype(np.float64)\n",
    "\n",
    "ISSUE IS THAT WE RUN INTO MEMORY ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data and test_data are 2 lists of np.array images\n",
    "# need to preprocess images a bit more first\n",
    "\n",
    "# make img file (1, 224, 224, 3)\n",
    "temp = [np.expand_dims(image, axis = 0) for image in train_dat]\n",
    "train_data2 = [preprocess_input(image, dim_ordering =  'tf') for image in temp]\n",
    "#test_data = [preprocess_input(np.expand_dims(image, axis = 0)) for image in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vgg16.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"block1_conv1\")`\n",
      "  x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
      "vgg16.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"block1_conv2\")`\n",
      "  x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
      "vgg16.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"block2_conv1\")`\n",
      "  x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
      "vgg16.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"block2_conv2\")`\n",
      "  x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
      "vgg16.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"block3_conv1\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
      "vgg16.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"block3_conv2\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
      "vgg16.py:91: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"block3_conv3\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
      "vgg16.py:95: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"block4_conv1\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
      "vgg16.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"block4_conv2\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
      "vgg16.py:97: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"block4_conv3\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
      "vgg16.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"block5_conv1\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
      "vgg16.py:102: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"block5_conv2\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
      "vgg16.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"block5_conv3\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = VGG16(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [16:00<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# classify the image\n",
    "preds = [model.predict(image) for image in tqdm(train_data2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To speed up time, don't run the line above.\n",
    "Instead, load the pickle file **preds.pl** and run the code 2 lines below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"preds.pl\", 'wb') # .pl is a pickle file\n",
    "pickle.dump(preds, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"preds.pl\", \"rb\")\n",
    "preds = cPickle.load(f) # load PPMI matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'n02123597', u'Siamese_cat'],\n",
       " [u'n03207941', u'dishwasher'],\n",
       " [u'n02123597', u'Siamese_cat'],\n",
       " [u'n02124075', u'Egyptian_cat'],\n",
       " [u'n02123159', u'tiger_cat']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [decode_predictions(pred)[0] for pred in preds]\n",
    "results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_results_ids = [decode_predictions(pred)[0][0] for pred in preds]\n",
    "top_results_lab = [decode_predictions(pred)[0][1] for pred in preds]\n",
    "# labs = [res[1] for res in top_results]\n",
    "# confs = [conf[2] for conf in top_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Need opencv to use the below code._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # display the predictions to our screen\n",
    "# print(\"ImageNet ID: {}, Label: {}\".format(inID, label))\n",
    "# cv2.putText(orig, \"Label: {}\".format(label), (10, 30),\n",
    "# \tcv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "# cv2.imshow(\"Classification\", orig)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Steps:\n",
    "1. Take **labels** and figure out if cat or dog based on classification output list. {:|:}\n",
    "2. Calculate accuracy. {:|:}\n",
    "3. Modify model if needed.\n",
    "4. Try on other CNNs.\n",
    "5. profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in Imagenet classications groupings for cats and dogs\n",
    "with open('cats.txt') as f:\n",
    "    cats = [line.rstrip()[0:9] for line in f]\n",
    "with open('dogs.txt') as f:\n",
    "    dogs = [line.rstrip()[0:9] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cat_or_dog(class_id):\n",
    "#     \"\"\"Returns generalized classification of cat or dog\"\"\"\n",
    "#     if class_id in cats: return 'cat'\n",
    "#     if class_id in dogs: return 'dog'\n",
    "#     return 'non' # non-binary case\n",
    "    \n",
    "def one_or_zero(class_id):\n",
    "    \"\"\"Returns generalize classification of cat or dog as bool\"\"\"\n",
    "    if class_id in cats: return 0\n",
    "    if class_id in dogs: return 1\n",
    "    return 420 # non-binary case\n",
    "    \n",
    "from operator import eq\n",
    "def calculate_accuracy(pred_labels, true_labels):\n",
    "    \"\"\"Calculates accuracy\"\"\"\n",
    "    return sum(map(eq, pred_labels, true_labels)) / float(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, u'Siamese_cat'),\n",
       " (420, u'dishwasher'),\n",
       " (0, u'Siamese_cat'),\n",
       " (0, u'Egyptian_cat'),\n",
       " (0, u'tiger_cat')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_class = [one_or_zero(id) for id in top_results_ids]\n",
    "[(class_,lab_) for (class_,lab_) in zip(simple_class, top_results_lab)][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(simple_class, train_labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
